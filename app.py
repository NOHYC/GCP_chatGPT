import streamlit as st
from langchain_core.messages.chat import ChatMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

st.title("ğŸ”‘ OpenAI API í‚¤ ì…ë ¥ GPT")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "api_key" not in st.session_state:
    st.session_state["api_key"] = None
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì‚¬ìš©ìë¡œë¶€í„° API í‚¤ ì…ë ¥ ë°›ê¸°
if st.session_state["api_key"] is None:
    api_key_input = st.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    if api_key_input:
        st.session_state["api_key"] = api_key_input
        st.rerun()  # í‚¤ê°€ ì…ë ¥ë˜ë©´ í˜ì´ì§€ ë¦¬ë¡œë“œë¡œ ì ìš©
else:
    # ë©”ì‹œì§€ ì…ë ¥ UI
    user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”")

    # ì²´ì¸ ìƒì„± í•¨ìˆ˜
    def create_chain():
        prompt = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI assistantì…ë‹ˆë‹¤."),
            ("user", "#Question:\n{question}"),
        ])
        llm = ChatOpenAI(
            model_name="gpt-4o",
            temperature=0,
            openai_api_key=st.session_state["api_key"]
        )
        output_parser = StrOutputParser()
        return prompt | llm | output_parser

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if user_input:
        add_message = lambda role, msg: st.session_state["messages"].append(
            ChatMessage(role=role, content=msg)
        )

        add_message("user", user_input)
        chain = create_chain()
        response = chain.invoke({"question": user_input})
        add_message("ai", response)

    # ì±„íŒ… ê¸°ë¡ ì¶œë ¥
    for msg in st.session_state["messages"]:
        with st.chat_message(msg.role):
            st.markdown(msg.content)

